{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text extraction from pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Headings kamen von VLM (Claude)\n",
    "- Code wurde nur kopiert aus Google Colab, aber noch nicht Ã¼berbearbeitet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install -y tesseract-ocr\n",
    "!sudo apt-get install -y tesseract-ocr-eng\n",
    "!sudo apt-get install -y tesseract-ocr-deu\n",
    "!sudo apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "class OCR:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize OCR pipeline for processing manuals in English and German\n",
    "        \"\"\"\n",
    "        # Verify language support\n",
    "        available_langs = pytesseract.get_languages()\n",
    "        required_langs = ['eng', 'deu']\n",
    "        missing_langs = [lang for lang in required_langs if lang not in available_langs]\n",
    "\n",
    "        if missing_langs:\n",
    "            raise RuntimeError(\n",
    "                f\"Missing required language packs: {missing_langs}. \"\n",
    "                \"Please install them using:\\n\"\n",
    "                \"Linux: sudo apt-get install tesseract-ocr-[lang]\\n\"\n",
    "                \"Windows: Download .traineddata files to tessdata directory\"\n",
    "            )\n",
    "\n",
    "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess image optimized for manual/document text\n",
    "        \"\"\"\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "\n",
    "        # Apply adaptive thresholding - works better for text documents\n",
    "        thresh = cv2.adaptiveThreshold(\n",
    "            gray,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            11,\n",
    "            2\n",
    "        )\n",
    "\n",
    "        # Denoise\n",
    "        denoised = cv2.fastNlMeansDenoising(thresh)\n",
    "\n",
    "        return denoised\n",
    "\n",
    "    def process_page(self, pil_image: Image.Image, i, title) -> Dict:\n",
    "        \"\"\"\n",
    "        Process a single page, optimized for manual text\n",
    "        \"\"\"\n",
    "        # Convert PIL to CV2 for preprocessing\n",
    "        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Preprocess\n",
    "        processed = self.preprocess_image(cv_image)\n",
    "\n",
    "        # OCR Configuration for manual text\n",
    "        custom_config = r'--psm 3 -l eng+deu'\n",
    "\n",
    "        # Get text\n",
    "        text = pytesseract.image_to_string(\n",
    "            processed,\n",
    "            config=custom_config\n",
    "        ).strip()\n",
    "\n",
    "        return {\n",
    "            'image': pil_image,\n",
    "            'title': title,\n",
    "            'text': text,\n",
    "            'page_number': i+1\n",
    "        }\n",
    "\n",
    "    def process_pdf(self, pdf_path: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Process PDF and return list of dictionaries containing PIL image and text\n",
    "\n",
    "        Returns:\n",
    "            List of dictionaries with format:\n",
    "            {\n",
    "                'image': PIL.Image,\n",
    "                'text': str\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert PDF to images with higher DPI for better OCR\n",
    "            pages = convert_from_path(\n",
    "                pdf_path,\n",
    "                dpi=200,\n",
    "                fmt='pil'  # Ensure PIL format\n",
    "            )\n",
    "\n",
    "            # Process each page\n",
    "            results = []\n",
    "            for i, page in tqdm(enumerate(pages), desc = \"Processing pages\", total = len(pages)):\n",
    "                result = self.process_page(page, i, pdf_path[:-4])\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error processing PDF {pdf_path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OCR, Layout Analysis und Markdown Extraction mit Dockling\n",
    "- Kann auf CPU oder GPU laufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q docling\n",
    "!sudo apt-get install poppler-utils -y\n",
    "!pip install -q pdf2image\n",
    "!pip install -q -U  PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann auch dockling mit tesseract konifgurieren. Default ist easy-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
    "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "\n",
    "model = StandardPdfPipeline.download_models_hf()\n",
    "# model = \"/local/path/to/artifacts\"\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(artifacts_path=model)\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split each page of pdf to own pdf\n",
    "- extract markdown from page pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"\n",
    "    Create a key for natural sorting of strings containing numbers.\n",
    "\n",
    "    Args:\n",
    "        s (str): Input string\n",
    "\n",
    "    Returns:\n",
    "        list: List of components for natural sorting\n",
    "    \"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def split_pdf_with_paths(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Split a PDF file into individual pages, save each page as a separate PDF,\n",
    "    and return sorted paths of generated files.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Path to the input PDF file\n",
    "        output_folder (str): Directory where individual pages will be saved\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of paths to generated PDF files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # List to store generated file paths\n",
    "    generated_paths = []\n",
    "\n",
    "    # Open the PDF file\n",
    "    try:\n",
    "        pdf = PdfReader(input_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening PDF file: {e}\")\n",
    "        return generated_paths\n",
    "\n",
    "    # Get the total number of pages\n",
    "    total_pages = len(pdf.pages)\n",
    "\n",
    "    # Extract the filename without extension\n",
    "    base_filename = os.path.splitext(os.path.basename(input_path))[0]\n",
    "\n",
    "    # Process each page\n",
    "    for page_num in range(total_pages):\n",
    "        # Create a PDF writer object\n",
    "        pdf_writer = PdfWriter()\n",
    "\n",
    "        # Add the current page\n",
    "        pdf_writer.add_page(pdf.pages[page_num])\n",
    "\n",
    "        # Generate output filename\n",
    "        output_filename = f\"{base_filename}_page_{page_num + 1}.pdf\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        # Save the page to a new PDF\n",
    "        try:\n",
    "            with open(output_path, 'wb') as output_file:\n",
    "                pdf_writer.write(output_file)\n",
    "            generated_paths.append(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving page {page_num + 1}: {e}\")\n",
    "\n",
    "    # Sort the paths naturally\n",
    "    generated_paths.sort(key=natural_sort_key)\n",
    "    return generated_paths\n",
    "\n",
    "def process_directory(directory):\n",
    "    \"\"\"\n",
    "    Process all PDFs in a directory, split them, and return all generated paths.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory containing PDF files\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of all generated PDF paths\n",
    "    \"\"\"\n",
    "    # Get all PDF files in directory\n",
    "    pdf_files = [f for f in os.listdir(directory) if f.endswith('.pdf')]\n",
    "    all_generated_paths = []\n",
    "\n",
    "    # Process each PDF file\n",
    "    for pdf_file in pdf_files:\n",
    "        input_path = os.path.join(directory, pdf_file)\n",
    "        output_folder = os.path.join(directory, 'split_pdfs')\n",
    "        paths = split_pdf_with_paths(input_path, output_folder)\n",
    "        all_generated_paths.extend(paths)\n",
    "\n",
    "    # Sort all paths naturally\n",
    "    all_generated_paths.sort(key=natural_sort_key)\n",
    "    return all_generated_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# list of dicts with pdf as title\n",
    "pdfs = list({\"title\": item} for item in list(set(item[\"title\"] for item in data)))\n",
    "\n",
    "all_pages = list()\n",
    "\n",
    "for pdf in pdfs:\n",
    "    title = pdf[\"title\"]\n",
    "    print(title)\n",
    "    path = f\"/content/driv#e/MyDrive/Pages/{title}\"\n",
    "    source = f\"/content/drive/MyDrive/MiR200/{title}.pdf\"\n",
    "    paths = split_pdf_with_paths(source, path)\n",
    "    pages = list()\n",
    "    for p in tqdm(paths, total=len(paths)):\n",
    "        page = dict()\n",
    "        markdown = converter.convert(p).document.export_to_markdown()\n",
    "        # replace image placeholder, etc\n",
    "        markdown_trans = markdown.replace(\" l \", \" \").replace(\"<!-- image -->\", \"\").replace(\"\\n\\n\\n\", \"\")\n",
    "        i = 1\n",
    "        page[\"title\"] = title\n",
    "        page[\"page_number\"] = p.split(\"_\")[-1].split(\".\")[0]\n",
    "        page[\"text\"] = markdown_trans\n",
    "        pages.append(page)\n",
    "    all_pages.extend(pages)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
